import numpy as np
import logging
from typing import Dict, Any, List, Optional, AsyncIterator
from sentence_transformers import SentenceTransformer
from .base_model import BaseModel, ModelResponse, ModelConfig, ModelCapability

logger = logging.getLogger(__name__)

class EmbeddingModel(BaseModel):
    """Multilingual embedding model for RAG system"""
    
    def __init__(self, config: ModelConfig = None):
        if config is None:
            config = ModelConfig(
                name="multilingual-e5-large",
                model_id="intfloat/multilingual-E5-large",
                capabilities=[ModelCapability.MULTILINGUAL],
                max_tokens=512,
                temperature=0.0,
                is_primary=True,
                priority=1
            )
        
        super().__init__(config)
        self.model_name = config.model_id
        self.embedding_dim = 1024  # E5-large dimension
        
        try:
            self.model = SentenceTransformer(self.model_name)
            logger.info(f"Initialized embedding model: {self.config.name}")
        except Exception as e:
            logger.error(f"Failed to initialize embedding model {self.config.name}: {e}")
            self.is_available = False
    
    async def generate_response(
        self, 
        prompt: str, 
        context: Dict[str, Any] = None,
        system_prompt: str = None,
        tools: List[Dict] = None
    ) -> ModelResponse:
        """Embedding models don't generate text responses"""
        raise NotImplementedError("EmbeddingModel does not support text generation")
    
    async def generate_streaming_response(
        self,
        prompt: str,
        context: Dict[str, Any] = None,
        system_prompt: str = None
    ) -> AsyncIterator[str]:
        """Embedding models don't support streaming text responses"""
        raise NotImplementedError("EmbeddingModel does not support streaming text generation")
    
    async def generate_embedding(self, text: str) -> List[float]:
        """Generate embeddings for text"""
        try:
            # Add E5 prefix for better performance
            if isinstance(text, str):
                text = f"query: {text}"  # For queries
            
            embedding = self.model.encode(text, normalize_embeddings=True)
            return embedding.tolist()
            
        except Exception as e:
            logger.error(f"Error generating embedding: {e}")
            self.mark_error()
            raise
    
    async def embed_documents(self, documents: List[str]) -> List[List[float]]:
        """Generate embeddings for multiple documents"""
        try:
            # Add E5 prefix for documents
            docs_with_prefix = [f"passage: {doc}" for doc in documents]
            embeddings = self.model.encode(docs_with_prefix, normalize_embeddings=True)
            return embeddings.tolist()
            
        except Exception as e:
            logger.error(f"Error generating document embeddings: {e}")
            self.mark_error()
            raise
    
    async def embed_query(self, query: str) -> List[float]:
        """Generate embedding for a query (with query prefix)"""
        return await self.generate_embedding(query)
    
    async def embed_passage(self, passage: str) -> List[float]:
        """Generate embedding for a passage (with passage prefix)"""
        try:
            text_with_prefix = f"passage: {passage}"
            embedding = self.model.encode(text_with_prefix, normalize_embeddings=True)
            return embedding.tolist()
            
        except Exception as e:
            logger.error(f"Error generating passage embedding: {e}")
            self.mark_error()
            raise
    
    async def health_check(self) -> bool:
        try:
            # Test with a simple Vietnamese text
            test_text = "Xin chÃ o"
            embedding = await self.generate_embedding(test_text)
            
            if len(embedding) == self.embedding_dim:
                self.is_available = True
                self.reset_errors()
                return True
            else:
                self.is_available = False
                return False
                
        except Exception as e:
            logger.error(f"Health check failed for {self.config.name}: {e}")
            self.is_available = False
            return False
    
    def get_embedding_dimension(self) -> int:
        """Get the dimension of embeddings generated by this model"""
        return self.embedding_dim
    
    def get_model_info(self) -> Dict[str, Any]:
        """Get detailed model information"""
        info = super().get_model_info()
        info.update({
            "embedding_dimension": self.embedding_dim,
            "model_name": self.model_name
        })
        return info